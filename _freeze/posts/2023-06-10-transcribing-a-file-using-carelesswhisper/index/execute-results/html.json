{
  "hash": "e298f8325fd5c7687995d5a044b944cf",
  "result": {
    "markdown": "---\ntitle: \"Transcribing A File Using carelesswhisper\"\nsubtitle: |\n  Using the carelesswhisper library to transcribe a full audio file.\ndate: 2023-06-10\ncategories: [R, audio]\neditor_options:\n  chunk_output_type: console\nbibliography: refs.bib\n---\n\n\n## TL;DR\n\nYou can iterate through an audio file and transcribe it using the new `carelesswhisper` package [@cool_whisper].\n\n## carelesswhisper\n\nIf you don't follow coolbutuseless on Mastodon, you are missing out, especially if you want to know about really intriguing R packages [@cool_mastodon].\nJust this week, they released a new R package built upon the `whisper` C library [@cool_whisper].\nAlthough I don't do any actual work with audio, especially human audio that one might want to do automatic speech recognition or transcription with, I dug into it to see if it would be possible to actually transcribe a full audio file.\n\n## Setup\n\nWe are going to need a few packages besides `carelesswhisper`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for transcription\nlibrary(carelesswhisper)\n# for converting from m4a\nlibrary(av)\n# for audio processing\nlibrary(tuneR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'tuneR'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:av':\n\n    sine\n```\n:::\n:::\n\n\nWe also need an audio file.\nI decided to download an episode of Holderness Family Laughs [@holderness_vacation], and see if we can transcribe it.\nI used yt-dlp to download and convert to audio [@yt_dlp].\n\n```bash\nyt-dlp https://youtu.be/DFM4Ey5oyhI -x --audio-format=m4a\n```\n\n## Conversion\n\nNow, we don't want to convert the whole thing, because it creates a giant piece of audio that will then have to be loaded into memory.\nJust our 5 minute Holderness episode is 69 MB on disk.\nSo for longer pieces of audio it would be even worse.\nHowever, we can do piecewise conversion and transcription over the length of the file.\n\nWhen we do the conversion, we do have to keep a couple of things in mind about what `carelesswhisper` expects.\nIt wants single channel, 16 KHz files.\nThis can be done during conversion.\nThe other thing it expects is a range of values between -1 and 1.\nThis we can take care of after conversion.\n\nSo we will write a function to do the conversion, read in the file, and do the transcription.\nWe will also overlap the time steps by 2 seconds, so that if we cut a word off in a previous conversion, then we should get the full thing in the next one.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate time indexes for transcription\nsplit_time = function(audio_length)\n{\n  n_piece = ceiling(audio_length / 30) + 2\n  out_time = vector(\"list\", n_piece)\n  start_time = 0\n  for (i_piece in seq_len(n_piece)) {\n    if (start_time > audio_length) {\n      break()\n    }\n    out_time[[i_piece]] = c(start = start_time,\n                                         end = min(c(start_time + 30, audio_length)))\n    start_time = start_time + 28\n  }\n  \n  not_null = purrr::map_lgl(out_time, \\(x){!is.null(x)})\n  out_time[not_null]\n}\n\n# rescale the values in the wav object\nrescale_wav = function(wav_object)\n{\n  wav_values = wav_object@left\n  wav_range = max(abs(wav_values))\n  wav_sign = sign(wav_values)\n  wav_fraction = abs(wav_values) / wav_range\n  wav_convert = wav_sign * wav_fraction\n  wav_convert\n}\n\n# do the actual conversion and transcription\ninner_convert_transcribe = function(time_index, audio_file, whisper_model)\n{\n  out_wav = av::av_audio_convert(audio_file, output = \"tmp.wav\", channels = 1,\n                                 sample_rate = 16000, start_time = time_index[\"start\"],\n                                 total_time = time_index[\"end\"] - time_index[\"start\"],\n                                 verbose = FALSE)\n  in_audio = tuneR::readWave(\"tmp.wav\")\n  scaled_audio = rescale_wav(in_audio)\n  transcribed = carelesswhisper::whisper(whisper_model, scaled_audio)\n  transcribed\n}\n\n# convert an actual file\nconvert_transcribe = function(audio_file)\n{\n  # audio_file = \"posts/2023-06-10-transcribing-a-file-using-carelesswhisper/20s vs 40s Vacation [DFM4Ey5oyhI].m4a\"\n  audio_info = av::av_media_info(audio_file)\n  audio_length = audio_info$duration\n  \n  time_splits = split_time(audio_length)\n  whisper_model = carelesswhisper::whisper_init()\n  transcribed_data = purrr::map(time_splits,\n                                inner_convert_transcribe,\n                                audio_file,\n                                whisper_model)\n  file.remove(\"tmp.wav\")\n  transcribed_data\n}\n```\n:::\n\n\nOK, so we have our four files, lets see if we can run through the entire 5 minutes.\nAnd see how long it takes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntictoc::tic()\n# audio_file = \"posts/2023-06-10-transcribing-a-file-using-carelesswhisper/20s vs 40s Vacation [DFM4Ey5oyhI].m4a\"\nholderness_transcribed = convert_transcribe(audio_file)\ntictoc::toc()\n```\n:::\n\n\nSo this took just longer than the time of the video itself, which honestly isn't too bad.\nThe conversion of small bits of file, and then re-scaling to work with `whisper`, don't seem to be imposing much overhead.\nIs the transcription perfect?\nNo.\nIs it pretty decent?\nI think so, especially given that we can do it all locally, from our own audio file.\nThe only other free way I know to do this is using \"Voice Typing\" in Google Docs, which is only accessible from the Chrome browser, and means putting your audio through Google's servers.\n\nAlso, `carelesswhisper` default is to use the smallest possible model.\nThere may be other models that will work on your machine, depending on how much RAM you have available.\nThe `carelesswhisper` README mentions how to use other speech recognition models from the `whisper` website [@cool_whisper].\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}